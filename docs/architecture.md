## ai-smartcloudops Architecture

This document outlines the system architecture aligned with the Phase Plan in `docs/phase_plan.md`.

### High-level Overview
- Local-first workflow with optional AWS Free Tier integration
- Modular pipeline: ingestion → monitoring → AI analysis → remediation → dashboard
- Prometheus + Grafana for observability (optional infra scaffolding)

```mermaid
graph TD
    %% Actors
    Dev[Developer / CI]:::actor -->|runs pytest / main.py| App[ai-smartcloudops]

    %% Core pipeline (local)
    subgraph Core[Core Application (local)]
        DI[data_ingestion.py\nfetch_metrics()] -->|writes| Store[(metrics.json)]
        Mon[monitor.py\nget_latest_metrics()] -->|reads| Store
        Mon --> AI[anomaly_detection.py\ndetect_anomaly()]
        AI --> AR[auto_remediate.py\nremediate_action()]
        UI[dashboard.py\nFlask] -->|shows| Mon
        UI --> AI
    end

    %% Orchestration
    App -->|orchestrates| Main[main.py]
    Main --> DI
    Main --> Mon
    Main --> AI
    Main --> AR
    Main --> UI

    %% Config
    CFG[config/aws_targets.json]:::cfg

    %% Observability (infra)
    subgraph Obs[Observability (optional)]
        subgraph Prom[Prometheus]
            FS[file_sd/app-and-node.json]
        end
        G[Grafana]
        NE[Node Exporter]:::aws
    end

    %% AWS and external services (optional)
    subgraph AWS[AWS (optional)]
        CW[CloudWatch]:::aws
        S3[(S3 Logs)]:::aws
        EC2[EC2 App/Node]:::aws
    end

    %% Relations optional/live
    DI -. live=True .-> CW
    AR -. log .-> S3
    EC2 -. exposes .-> NE
    CFG -. drives .-> FS
    Prom -. scrapes .-> NE
    G -. queries .-> Prom

    classDef actor fill:#fff,stroke:#666,stroke-width:1px;
    classDef aws fill:#f3f8ff,stroke:#3b82f6,stroke-width:1px;
    classDef cfg fill:#fff7ed,stroke:#fb923c,stroke-width:1px;
```

### Components and Responsibilities
- src/data_ingestion.py
  - fetch_metrics(file_path, live=False): write synthetic metrics locally; when live=True (later phases) read from CloudWatch/EC2
- src/monitor.py
  - get_latest_metrics(file_path, live=False): read metrics from JSON (local default)
- src/anomaly_detection.py
  - detect_anomaly(metrics): rule or model-based anomaly flag; starts rule-based (>90%) per plan
- src/auto_remediate.py
  - remediate_action(issue): simulate remediation action; later log to S3
- src/dashboard.py
  - Flask endpoints: /, /health, /metrics (added in dashboard phase)
- src/main.py
  - Orchestrates the end-to-end flow for integration tests

### Infrastructure (optional scaffolding per plan)
- infra/prometheus/
  - prometheus.yml and file_sd/app-and-node.json generated by scripts (later)
- infra/scripts/
  - prometheus_config.py to regenerate file-SD JSON from config/aws_targets.json
- config/aws_targets.json
  - Source of truth for monitored targets (EC2 IPs/ports)

### Testing Strategy (summarized)
- tests/ with phase markers (phase0..phase7) and optional aws_live
- Local synthetic metrics by default; AWS calls mocked unless AWS_LIVE=1
- Each phase adds focused tests before proceeding to the next phase

### Data Flow (local default)
1. data_ingestion.fetch_metrics() → metrics.json
2. monitor.get_latest_metrics() → dict with cpu/memory
3. anomaly_detection.detect_anomaly() → boolean flag
4. auto_remediate.remediate_action() → action string/log
5. dashboard surfaces the latest metrics and anomaly state

### Deployment Notes (later phases)
- Local development: run Flask dashboard locally; tests with pytest
- AWS Free Tier (optional): EC2 for App and Mon, Prometheus scraping Node Exporter, Grafana dashboards
- Security: keep credentials in environment variables; avoid committing secrets


